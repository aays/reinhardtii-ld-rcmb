{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "\n",
    "1. Bin the genome by diversity\n",
    "2. Assign COs to bins based on the diversity bin associated with their location in the genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, gzip\n",
    "from annotation import annotation_table\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pysam import TabixFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from annotation import annotation_table\n",
    "\n",
    "\n",
    "############################################################################################################################################\n",
    "def alleles_to_pi(alleles, min_called=None, MAF=True, AAF=False, ref_base = None, biallelic_only=None): \n",
    "    allele_list = [int(i) for i in alleles.split(':')]\n",
    "    num_alleles = sum(allele_list)\n",
    "    if min_called and num_alleles <= min_called:\n",
    "        return (None, None, num_alleles)\n",
    "    if biallelic_only and sorted(allele_list)[1] >0:\n",
    "        return (None, None, num_alleles)\n",
    "    try:\n",
    "        MAF = sorted(allele_list)[-2]/num_alleles\n",
    "        pi = (float(num_alleles)/(num_alleles - 1.0)) * (2.0 * MAF * (1-MAF))   \n",
    "    except ZeroDivisionError:\n",
    "        MAF = None\n",
    "        pi = None\n",
    "    return (MAF, pi, num_alleles)\n",
    "############################################################################################################################################\n",
    "\n",
    "chromosomes  = ['chromosome_1', 'chromosome_2', 'chromosome_3', 'chromosome_4', 'chromosome_5', 'chromosome_6', 'chromosome_7', 'chromosome_8', 'chromosome_9', 'chromosome_10', 'chromosome_11', 'chromosome_12', 'chromosome_13', 'chromosome_14', 'chromosome_15', 'chromosome_16', 'chromosome_17', 'scaffold_18', 'scaffold_19', 'scaffold_20', 'scaffold_21', 'scaffold_22', 'scaffold_23', 'scaffold_24', 'scaffold_25', 'scaffold_26', 'scaffold_27', 'scaffold_28', 'scaffold_29', 'scaffold_30', 'scaffold_31', 'scaffold_32', 'scaffold_33', 'scaffold_34', 'scaffold_35', 'scaffold_36', 'scaffold_37', 'scaffold_38', 'scaffold_39', 'scaffold_40', 'scaffold_41', 'scaffold_42', 'scaffold_43', 'scaffold_44', 'scaffold_45', 'scaffold_46', 'scaffold_47', 'scaffold_48', 'scaffold_49', 'scaffold_50', 'scaffold_51', 'scaffold_52', 'scaffold_53', 'scaffold_54', 'cpDNA', 'mtDNA', 'mtMinus']\n",
    "ch_lengths = [8033585, 9223677, 9219486, 4091191, 3500558, 9023763, 6421821, 5033832, 7956127, 6576019, 3826814, 9730733, 5206065, 4157777, 1922860, 7783580, 7188315, 271631, 219038, 200793, 189560, 163774, 127913, 127161, 102191, 80213, 55320, 55278, 52813, 52376, 48183, 42264, 39192, 33576, 32450, 25399, 24537, 24437, 22408, 22082, 21325, 21000, 20974, 17736, 16939, 16627, 14746, 14165, 13462, 12727, 11225, 6241, 2479, 2277, 203828, 15758, 345555]\n",
    "\n",
    "ch_data = {}\n",
    "for i in range(len(chromosomes)):\n",
    "     ch_data[chromosomes[i]] = ch_lengths[i]\n",
    "\n",
    "from pysam import TabixFile        \n",
    "annotation_table_file= '/scratch/research/references/chlamydomonas/5.3_chlamy_w_organelles_mt_minus/annotation/concatenated_GFF/annotation_table.txt.gz'\n",
    "annotation_tabix = TabixFile(filename= annotation_table_file)\n",
    "############################################################################################################################################\n",
    "\n",
    "\n",
    "wdw_size =10000\n",
    "\n",
    "\n",
    "#c = chromosomes[int(sys.argv[1])-1]\n",
    "c = chromosomes[1]\n",
    "#o=open('pi_windows.%s.txt' %c, 'w')\n",
    "o=sys.stdout\n",
    "print(c, ch_data[c])\n",
    "for w in range(0,ch_data[c],wdw_size):\n",
    "    start, end = w,min(w+wdw_size,ch_data[c])\n",
    "    pi, pi_denominator, functional, intergenic, intronic, fold4 = [0]*6\n",
    "    for site in annotation_tabix.fetch(c, start, end):\n",
    "        site = annotation_table.annotation_line(site)\n",
    "        if '1' in [site.intergenic, site.intronic, site.fold4]:\n",
    "            MAF, site_pi, alleles = alleles_to_pi(site.quebec_alleles, min_called=12,biallelic_only=True)\n",
    "            if site_pi !=None:\n",
    "                pi += site_pi\n",
    "                pi_denominator += 1\n",
    "        if '1' in [site.utr5, site.utr3, site.fold0, site.fold2]:\n",
    "            functional +=1\n",
    "        for a in ['intergenic', 'intronic', 'fold4']:\n",
    "            exec('%s += int(site.%s)' %(a,a))  \n",
    "    \n",
    "    #Summarise statistics\n",
    "    try:\n",
    "        o.write(\"\\t\".join([str(i) for i in [c, start, end, pi/pi_denominator, pi_denominator, functional, intergenic, intronic, fold4]]) + \"\\n\")\n",
    "    except ZeroDivisionError:\n",
    "        o.write(\"\\t\".join([str(i) for i in [c, start, end, 'None', pi_denominator, functional, intergenic, intronic, fold4]]) + \"\\n\")\n",
    "\n",
    "o.close()\n",
    "\n",
    "#parallel -i \"python3 ./pi_windows.py {}\" 1..57"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used a script of the above cell to run the 57 chromosomes in parallel\n",
    "\n",
    "This is how you concatenate them \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \" \".join([\"pi_windows.%s.txt\" %i for i in chromosomes ])\n",
    "\n",
    "cmd = \"cat \" + x + \" >pi_windows.txt\"\n",
    "\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat pi_windows.chromosome_1.txt pi_windows.chromosome_2.txt \\\n",
    "pi_windows.chromosome_3.txt pi_windows.chromosome_4.txt \\\n",
    "pi_windows.chromosome_5.txt pi_windows.chromosome_6.txt \\\n",
    "pi_windows.chromosome_7.txt pi_windows.chromosome_8.txt \\\n",
    "pi_windows.chromosome_9.txt pi_windows.chromosome_10.txt \\\n",
    "pi_windows.chromosome_11.txt pi_windows.chromosome_12.txt \\\n",
    "pi_windows.chromosome_13.txt pi_windows.chromosome_14.txt \\\n",
    "pi_windows.chromosome_15.txt pi_windows.chromosome_16.txt \\\n",
    "pi_windows.chromosome_17.txt pi_windows.scaffold_18.txt \\\n",
    "pi_windows.scaffold_19.txt pi_windows.scaffold_20.txt \\\n",
    "pi_windows.scaffold_21.txt pi_windows.scaffold_22.txt \\\n",
    "pi_windows.scaffold_23.txt pi_windows.scaffold_24.txt pi_windows.scaffold_25.txt pi_windows.scaffold_26.txt pi_windows.scaffold_27.txt pi_windows.scaffold_28.txt pi_windows.scaffold_29.txt pi_windows.scaffold_30.txt pi_windows.scaffold_31.txt pi_windows.scaffold_32.txt pi_windows.scaffold_33.txt pi_windows.scaffold_34.txt pi_windows.scaffold_35.txt pi_windows.scaffold_36.txt pi_windows.scaffold_37.txt pi_windows.scaffold_38.txt pi_windows.scaffold_39.txt pi_windows.scaffold_40.txt pi_windows.scaffold_41.txt pi_windows.scaffold_42.txt pi_windows.scaffold_43.txt pi_windows.scaffold_44.txt pi_windows.scaffold_45.txt pi_windows.scaffold_46.txt pi_windows.scaffold_47.txt pi_windows.scaffold_48.txt pi_windows.scaffold_49.txt pi_windows.scaffold_50.txt pi_windows.scaffold_51.txt pi_windows.scaffold_52.txt pi_windows.scaffold_53.txt pi_windows.scaffold_54.txt pi_windows.cpDNA.txt pi_windows.mtDNA.txt pi_windows.mtMinus.txt \\\n",
    ">pi_windows.10kbp.txt; wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bgzip -f pi_windows.10kbp.txt;wait\n",
    "tabix -s 1 -b 2 -e 3 -f  pi_windows.10kbp.txt.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_range = [0,0.1]\n",
    "bin_number = 50\n",
    "bin_width = (pi_range[1]-pi_range[0])/bin_number\n",
    "bins = [(i/1000,round(i/1000+bin_width,3)) for i in range(0,100,2)]\n",
    "#print(bins)\n",
    "pi_hist = {}\n",
    "for b in bins:\n",
    "    pi_hist[b] = {'sites':0, 'COs':0, 'functional':0, 'intergenic':0, \n",
    "                  'intronic':0, 'fold4':0}\n",
    "\n",
    "import gzip    \n",
    "min_sites = 500\n",
    "for l in gzip.open(\"pi_windows.10kbp.txt.gz\"):\n",
    "    # chromosome start end pi sites functional intergenic intronic fold4\n",
    "    #e.g. \"chromosome_1    10000   20000   0.01642010741618584     2250    932     8765    150     149\"\n",
    "    chromosome, start, end, pi, sites, functional, intergenic, intronic, fold4 = l.strip().split()\n",
    "    if pi != 'None' and int(sites) > min_sites:\n",
    "        for b in bins:\n",
    "            if b[0] <= float(pi) < b[-1]:\n",
    "                pi_hist[b]['sites'] += int(sites)\n",
    "                pi_hist[b]['functional'] += int(functional)\n",
    "                pi_hist[b]['intergenic'] += int(intergenic)\n",
    "                pi_hist[b]['intronic'] += int(intronic)\n",
    "                pi_hist[b]['fold4'] += int(fold4)\n",
    "                break\n",
    "\n",
    "\n",
    "pi_table = TabixFile(filename= \"pi_windows.10kbp.txt.gz\")\n",
    "for line in open(\"../all_break_points.txt\").readlines()[1:]:\n",
    "    cross, tetrad ,individual ,chromosome ,left_bound ,right_bound ,mid_point, length = line.strip().split()\n",
    "    #if int(length) > 1e4: continue\n",
    "    pi_line = pi_table.fetch(chromosome, int(mid_point)-1, int(mid_point)).next()\n",
    "    pi, sites = pi_line.strip().split()[3:5]\n",
    "    if int(sites) > min_sites and pi != \"None\":\n",
    "        for b in bins:\n",
    "            if b[0] <= float(pi) < b[-1]:\n",
    "                pi_hist[b]['COs'] += 1\n",
    "                break\n",
    "\n",
    "# for b in bins:\n",
    "#     print(b, \"\\t\", pi_hist[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "CO_density = []\n",
    "for b in bins:\n",
    "    try:\n",
    "        CO_density.append(pi_hist[b]['COs']/pi_hist[b]['sites'])\n",
    "    except ZeroDivisionError:\n",
    "        CO_density.append(0)\n",
    "\n",
    "        \n",
    "\n",
    "data= {'CO_density':CO_density, \\\n",
    "        'Diversity':[(b[0]+b[1])/2 for b in bins], \\\n",
    "        'bins': bins, \\\n",
    "        'sites':[pi_hist[b]['sites'] for b in bins],\n",
    "        'COs':[pi_hist[b]['COs'] for b in bins],\n",
    "        'functional':[pi_hist[b]['functional'] for b in bins],\n",
    "        'intergenic':[pi_hist[b]['intergenic'] for b in bins],\n",
    "        'intronic':[pi_hist[b]['intronic'] for b in bins],\n",
    "        'fold4':[pi_hist[b]['fold4'] for b in bins]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df.to_csv('pi_by_CO_density.10kbp.min500sites.txt')\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import scipy.stats  as stats\n",
    "\n",
    "\n",
    "#Do it with stats functions. \n",
    "\n",
    "#df_filter = df[(df.Diversity<0.05) & (df.Diversity > 0.001)]\n",
    "#df_filter = df[(df.sites >10000)]\n",
    "#df_filter = df[(df.COs >0)]\n",
    "df_filter = df[df.sites>100000]\n",
    "#df_filter = df\n",
    "df_filter['log_CO_density'] = np.log(df_filter.CO_density+1)\n",
    "\n",
    "df_filter.plot(kind='scatter',x='log_CO_density',y='Diversity', xlim=(0,0.00011))\n",
    "print(\"Correlation: \", df_filter.Diversity.corr(df_filter.log_CO_density))\n",
    "fit  = stats.pearsonr(df_filter['Diversity'], df_filter['log_CO_density'])\n",
    "print(fit)\n",
    "df.plot(kind ='bar', y='sites', x = 'Diversity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filter = df[(df.Diversity<0.05) & (df.Diversity > 0.001)]\n",
    "#df_filter = df[(df.sites >10000)]\n",
    "df_filter = df[(df.COs >0)]\n",
    "#df_filter = df\n",
    "\n",
    "df_filter['log_CO_density'] = np.log(df_filter.CO_density+1)\n",
    "\n",
    "df_filter\n",
    "df_filter.plot(kind='scatter',x='log_CO_density',y='Diversity', xlim = (0,0.00005))\n",
    "print(\"Correlation: \", df_filter.Diversity.corr(df_filter.log_CO_density))\n",
    "fit  = stats.pearsonr(df_filter['Diversity'], df_filter['log_CO_density'])\n",
    "print(fit)\n",
    "# df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filter = df[(df.Diversity<0.05) & (df.Diversity > 0.001)]\n",
    "#df_filter = df[(df.sites >10000)]\n",
    "df_filter = df[(df.COs >0)]\n",
    "#df_filter = df\n",
    "\n",
    "df_filter.plot(kind='scatter',x='CO_density',y='Diversity', xlim=(0,0.0001))\n",
    "print(\"Correlation: \", df_filter.Diversity.corr(df_filter.CO_density))\n",
    "fit  = stats.pearsonr(df_filter['Diversity'], df_filter['CO_density'])\n",
    "print(fit)\n",
    "df_filter"
   ]
  }
 ],
 "metadata": {
  "jupytext": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
